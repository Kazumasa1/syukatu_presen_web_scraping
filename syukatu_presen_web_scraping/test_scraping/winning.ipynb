{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "664481fb-9279-4d36-b173-00721dece411",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sm/cxsqyhg95x34kj03xss1t3mh0000gn/T/ipykernel_43797/114032172.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# サーバへの負荷を下げるためにsleep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# リンク先のHTML要素を取得\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import KOBO_URL\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# スクレイピング対象のサイトのURLのリストを取得\n",
    "winning_url = []\n",
    "winning_url = KOBO_URL.WINNING_URL_LIST\n",
    "\n",
    "# 入賞した作品を格納するリスト\n",
    "winning_list = []\n",
    "\n",
    "for n in range(2):\n",
    "# for n in range(len(winning_url)):\n",
    "    res = requests.get(winning_url[n])\n",
    "\n",
    "    # WebサイトのHTML要素を取得\n",
    "    soup = BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "    # li要素を取得\n",
    "    soup_li = soup.find_all('td', attrs={'class': 'course leftcell'})\n",
    "\n",
    "    # リンクを取得\n",
    "    link_list = []\n",
    "    for j in range(len(soup_li)):\n",
    "        soup_a = soup_li[j].find('a')\n",
    "\n",
    "        try:  \n",
    "            soup_a = soup_a.get('href')\n",
    "            link_list.append(soup_a)\n",
    "        except AttributeError as e:\n",
    "            continue\n",
    "\n",
    "\n",
    "    for j in range(len(link_list)):     \n",
    "        res_link = requests.get(KOBO_URL.WINNING_ROOT + link_list[j])\n",
    "        \n",
    "        # サーバへの負荷を下げるためにsleep\n",
    "        time.sleep(1)\n",
    "\n",
    "        # リンク先のHTML要素を取得\n",
    "        link_soup =  BeautifulSoup(res_link.content, 'html.parser')\n",
    "        link_soup_td = link_soup.find_all('td', attrs={'class': 'fixedwidth2'})\n",
    "\n",
    "        for k in range(len(link_soup_td)):\n",
    "            winning_list.append(link_soup_td[k].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7366650-7829-4eeb-8d31-f2cbf6cff182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# winning_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cffe057-1e6e-4074-9fab-e5a9ff7dac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import KOBO_URL\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# スクレイピング対象のサイトのURLを取得\n",
    "winning_url = KOBO_URL.WINNING_URL_LIST[1]\n",
    "res = requests.get(winning_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8edc97f-c6c4-49e8-94f6-19c3ad59a270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import KOBO_URL\n",
    "winning_url = []\n",
    "winning_url = KOBO_URL.WINNING_URL_LIST\n",
    "# winning_url[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d6a37dc-7227-42a7-ba7e-eb2d4c8bcc15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8661d0de-603b-460b-b541-9a70c97187bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WebサイトのHTML要素を取得\n",
    "soup = BeautifulSoup(res.content, 'html.parser')\n",
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c757a97a-ca4a-4035-9259-1371e940765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# li要素を取得\n",
    "soup_li = soup.find_all('td', attrs={'class': 'course leftcell'})\n",
    "# soup_li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4db38b55-c50f-4566-8ca8-4d21d2932ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'record/01tokyo.html'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(soup_li[0].find('a')).get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d997eeec-72a7-42bb-955e-1ca7c5dc7818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soup_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb753dfa-af63-45d5-a760-bcc68ce5b143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# リンクを取得\n",
    "link_list = []\n",
    "for n in range(len(soup_li)):\n",
    "    soup_a = soup_li[n].find('a')\n",
    "    \n",
    "    try:  \n",
    "        soup_a = soup_a.get('href')\n",
    "        link_list.append(soup_a)\n",
    "    except AttributeError as e:\n",
    "        continue\n",
    "    \n",
    "# link_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa0a9b6d-c3c7-4f6d-9847-452d963f7100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sss = KOBO_URL.WINNING_ROOT\n",
    "# sss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16ffb74f-5e6d-4696-88bb-3b8e9bba0992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_link = requests.get(KOBO_URL.WINNING_ROOT + link_list[30])\n",
    "res_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c78d89b7-2965-4ebb-a502-c81488c121d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# リンク先のHTML要素を取得\n",
    "link_soup =  BeautifulSoup(res_link.content, 'html.parser')\n",
    "link_soup_td = link_soup.find_all('td', attrs={'class': 'fixedwidth2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d3fcc104-fb09-43a7-926b-522e03e5b9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# link_soup_td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4bc843c2-2840-4c8c-84ed-eb079f974f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(link_soup_td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8095ffc-11a8-492e-aac7-9f0b041368ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入賞した作品を格納するリスト\n",
    "winning_list = []\n",
    "\n",
    "for n in range(len(link_soup_td)):\n",
    "    winning_list.append(link_soup_td[n].text)\n",
    "\n",
    "# winning_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2880b17d-13bd-4b74-91d1-d1535afcbbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_link = requests.get(KOBO_URL.WINNING_ROOT + link_list[1])\n",
    "link_soup =  BeautifulSoup(res_link.content, 'html.parser')\n",
    "link_soup_td = link_soup.find_all('td', attrs={'class': 'fixedwidth2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7f90bc3-08f9-4fa1-939b-2829378b820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(len(link_soup_td)):\n",
    "    winning_list.append(link_soup_td[n].text)\n",
    "\n",
    "# winning_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411c04b8-50c7-4185-803b-dcd0fd0de6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 応募リンクを配列に格納する\n",
    "link_list = []\n",
    "while_cnt = 0\n",
    "while True:\n",
    "    try:\n",
    "        soup_a = soup_li[while_cnt].find('a')\n",
    "        soup_a = soup_a.get('href')\n",
    "        link_list.append(soup_a)\n",
    "        \n",
    "    except IndexError as e:\n",
    "        break\n",
    "        \n",
    "    while_cnt += 1\n",
    "\n",
    "\n",
    "kobo_title_list = []\n",
    "kobo_feature_list = []\n",
    "kobo_info_list = []\n",
    "\n",
    "\n",
    "for n in range(len(link_list)):\n",
    "# for n in range(2):\n",
    "    # 情報を取得する公募ページに移動してHTTPを取得\n",
    "    kobo_url = link_list[n]\n",
    "    res_kobo = requests.get(kobo_url)\n",
    "    soup_kobo = BeautifulSoup(res_kobo.text, 'html.parser')\n",
    "    soup_kobo_dl = soup_kobo.find_all('dl')\n",
    "    \n",
    "    while_cnt = 0\n",
    "    while True:\n",
    "        try:\n",
    "            soup_kobo_dt = soup_kobo_dl[while_cnt].find_all('dt')\n",
    "            if '締切' == soup_kobo_dt[0].text:\n",
    "                break\n",
    "        except IndexError as e:\n",
    "            break\n",
    "        while_cnt += 1\n",
    "    \n",
    "    soup_kobo_dd = soup_kobo_dl[while_cnt].find_all('dd')\n",
    "    \n",
    "    kobo_info = {}\n",
    "    \n",
    "    # タイトルを追加\n",
    "    kobo_title = soup_li[n].find_all('h3')\n",
    "    kobo_title = kobo_title[0].text.replace('\\u3000', '')\n",
    "    kobo_info.setdefault('タイトル', kobo_title)\n",
    "    \n",
    "    # 応募リンクを追加\n",
    "    obo_link = ''\n",
    "    # 川柳の詳細ページのHTML要素の<a>タグのclass='btn-koushiki'の要素を取得\n",
    "    obo_link = soup_kobo.find_all('a', attrs={'class': 'btn-koushiki'})\n",
    "    obo_link = obo_link[0].get('href')\n",
    "    # 応募リンクをkobo_infoに追加\n",
    "    kobo_info.setdefault('応募リンク', obo_link)\n",
    "    \n",
    "    # 公募概要情報の取得・配列に格納\n",
    "    for j in range(len(soup_kobo_dd)):\n",
    "        kobo_feature_title = soup_kobo_dt[j].text\n",
    "        kobo_feature_title = kobo_feature_title.replace('\\u3000', ' ')\n",
    "        \n",
    "        # 項目名をデータベースのカラム名に変換\n",
    "        if '締切' == kobo_feature_title:\n",
    "            kobo_feature_title = '締切日'\n",
    "            \n",
    "            # 日付だけを抽出\n",
    "            kobo_feature = soup_kobo_dd[j].text.replace('\\u3000', ' ')\n",
    "            kobo_feature = kobo_feature.replace('\\n', '')\n",
    "            kobo_feature = kobo_feature.replace('\\t', '')\n",
    "            kobo_feature = kobo_feature.replace('\\r', '')\n",
    "            kobo_feature = re.match('20\\d\\d.\\d\\d.\\d\\d.', kobo_feature)\n",
    "            kobo_feature =  str(kobo_feature.group())\n",
    "            kobo_feature = kobo_feature.replace('年', '-')\n",
    "            kobo_feature = kobo_feature.replace('月', '-')\n",
    "            kobo_feature = kobo_feature.replace('日', '')\n",
    "            kobo_info.setdefault(kobo_feature_title, kobo_feature)\n",
    "            \n",
    "            continue\n",
    "            \n",
    "        elif '賞' == kobo_feature_title:\n",
    "            kobo_feature_title = '賞金'\n",
    "        elif '募集内容' == kobo_feature_title:\n",
    "            kobo_feature_title = '募集内容'\n",
    "        elif '参加資格' == kobo_feature_title:\n",
    "            kobo_feature_title = '応募資格'\n",
    "        elif '主催' == kobo_feature_title:\n",
    "            kobo_feature_title = '主催'\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        # HTML要素のテキストだけを取り出す\n",
    "        kobo_feature = soup_kobo_dd[j].text.replace('\\u3000', ' ')\n",
    "        kobo_feature = kobo_feature.replace('\\n', '')\n",
    "        kobo_feature = kobo_feature.replace('\\t', '')\n",
    "        kobo_feature = kobo_feature.replace('\\r', '')\n",
    "        kobo_info.setdefault(kobo_feature_title, kobo_feature)\n",
    "        \n",
    "    # kobo_infoの中身を並び替える\n",
    "    kobo_sort = {}\n",
    "    kobo_sort.setdefault('タイトル', kobo_info['タイトル'])\n",
    "    kobo_sort.setdefault('締切日', kobo_info['締切日'])\n",
    "    kobo_sort.setdefault('賞金', kobo_info['賞金'])\n",
    "    kobo_sort.setdefault('募集内容', kobo_info['募集内容'])\n",
    "    kobo_sort.setdefault('応募資格', kobo_info['応募資格'])\n",
    "    kobo_sort.setdefault('主催', kobo_info['主催'])\n",
    "    kobo_sort.setdefault('応募リンク', kobo_info['応募リンク'])\n",
    "    \n",
    "    # 公募情報を配列に格納\n",
    "    kobo_info_list.append(kobo_sort)\n",
    "    \n",
    "    # サーバへの負荷を下げるためにsleep\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "# csvで出力\n",
    "\n",
    "df = pd.DataFrame(kobo_info_list)\n",
    "\n",
    "# excelで文字化けしないようにutf_8_sigでエンコード\n",
    "df.to_csv('kobo_scraping.csv', encoding='utf_8_sig', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
